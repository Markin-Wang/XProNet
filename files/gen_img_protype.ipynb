{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74810fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nnQ\n",
    "import torchvision.models as models\n",
    "from modules.tokenizers import Tokenizer\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d464bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_agrs():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Data input settings\n",
    "    parser.add_argument('--image_dir', type=str, default='data/iu_xray/images/',\n",
    "                        help='the path to the directory containing the data.')\n",
    "    parser.add_argument('--ann_path', type=str, default='data/iu_xray/annotation.json',\n",
    "                        help='the path to the directory containing the data.')\n",
    "\n",
    "    # Data loader settings\n",
    "    parser.add_argument('--dataset_name', type=str, default='iu_xray', choices=['iu_xray', 'mimic_cxr'],\n",
    "                        help='the dataset to be used.')\n",
    "    parser.add_argument('--max_seq_length', type=int, default=60, help='the maximum sequence length of the reports.')\n",
    "    parser.add_argument('--threshold', type=int, default=3, help='the cut off frequency for the words.')\n",
    "    parser.add_argument('--num_workers', type=int, default=2, help='the number of workers for dataloader.')\n",
    "    parser.add_argument('--batch_size', type=int, default=16, help='the number of samples for a batch')\n",
    "\n",
    "    # Model settings (for visual extractor)\n",
    "    parser.add_argument('--visual_extractor', type=str, default='resnet101', help='the visual extractor to be used.')\n",
    "    parser.add_argument('--visual_extractor_pretrained', type=bool, default=True, help='whether to load the pretrained visual extractor')\n",
    "\n",
    "    # Model settings (for Transformer)\n",
    "    parser.add_argument('--d_model', type=int, default=512, help='the dimension of Transformer.')\n",
    "    parser.add_argument('--d_ff', type=int, default=512, help='the dimension of FFN.')\n",
    "    parser.add_argument('--d_vf', type=int, default=2048, help='the dimension of the patch features.')\n",
    "    parser.add_argument('--num_heads', type=int, default=8, help='the number of heads in Transformer.')\n",
    "    parser.add_argument('--num_layers', type=int, default=3, help='the number of layers of Transformer.')\n",
    "    parser.add_argument('--dropout', type=float, default=0.1, help='the dropout rate of Transformer.')\n",
    "    parser.add_argument('--logit_layers', type=int, default=1, help='the number of the logit layer.')\n",
    "    parser.add_argument('--bos_idx', type=int, default=0, help='the index of <bos>.')\n",
    "    parser.add_argument('--eos_idx', type=int, default=0, help='the index of <eos>.')\n",
    "    parser.add_argument('--pad_idx', type=int, default=0, help='the index of <pad>.')\n",
    "    parser.add_argument('--use_bn', type=int, default=0, help='whether to use batch normalization.')\n",
    "    parser.add_argument('--drop_prob_lm', type=float, default=0.5, help='the dropout rate of the output layer.')\n",
    "\n",
    "    # for Cross-modal Memory\n",
    "    parser.add_argument('--topk', type=int, default=32, help='the number of k.')\n",
    "    parser.add_argument('--cmm_size', type=int, default=2048, help='the numebr of cmm size.')\n",
    "    parser.add_argument('--cmm_dim', type=int, default=512, help='the dimension of cmm dimension.')\n",
    "\n",
    "    # Sample related\n",
    "    parser.add_argument('--sample_method', type=str, default='beam_search', help='the sample methods to sample a report.')\n",
    "    parser.add_argument('--beam_size', type=int, default=3, help='the beam size when beam searching.')\n",
    "    parser.add_argument('--temperature', type=float, default=1.0, help='the temperature when sampling.')\n",
    "    parser.add_argument('--sample_n', type=int, default=1, help='the sample number per image.')\n",
    "    parser.add_argument('--group_size', type=int, default=1, help='the group size.')\n",
    "    parser.add_argument('--output_logsoftmax', type=int, default=1, help='whether to output the probabilities.')\n",
    "    parser.add_argument('--decoding_constraint', type=int, default=0, help='whether decoding constraint.')\n",
    "    parser.add_argument('--block_trigrams', type=int, default=1, help='whether to use block trigrams.')\n",
    "\n",
    "    # Trainer settings\n",
    "    parser.add_argument('--n_gpu', type=int, default=1, help='the number of gpus to be used.')\n",
    "    parser.add_argument('--epochs', type=int, default=100, help='the number of training epochs.')\n",
    "    parser.add_argument('--save_dir', type=str, default='results/iu_xray', help='the patch to save the models.')\n",
    "    parser.add_argument('--record_dir', type=str, default='records/', help='the patch to save the results of experiments.')\n",
    "    parser.add_argument('--log_period', type=int, default=1000, help='the logging interval (in batches).')\n",
    "    parser.add_argument('--save_period', type=int, default=1, help='the saving period (in epochs).')\n",
    "    parser.add_argument('--monitor_mode', type=str, default='max', choices=['min', 'max'], help='whether to max or min the metric.')\n",
    "    parser.add_argument('--monitor_metric', type=str, default='BLEU_4', help='the metric to be monitored.')\n",
    "    parser.add_argument('--early_stop', type=int, default=50, help='the patience of training.')\n",
    "\n",
    "    # Optimization\n",
    "    parser.add_argument('--optim', type=str, default='Adam', help='the type of the optimizer.')\n",
    "    parser.add_argument('--lr_ve', type=float, default=5e-5, help='the learning rate for the visual extractor.')\n",
    "    parser.add_argument('--lr_ed', type=float, default=7e-4, help='the learning rate for the remaining parameters.')\n",
    "    parser.add_argument('--weight_decay', type=float, default=5e-5, help='the weight decay.')\n",
    "    parser.add_argument('--adam_betas', type=tuple, default=(0.9, 0.98), help='the weight decay.')\n",
    "    parser.add_argument('--adam_eps', type=float, default=1e-9, help='the weight decay.')\n",
    "    parser.add_argument('--amsgrad', type=bool, default=True, help='.')\n",
    "    parser.add_argument('--noamopt_warmup', type=int, default=5000, help='.')\n",
    "    parser.add_argument('--noamopt_factor', type=int, default=1, help='.')\n",
    "\n",
    "    # Learning Rate Scheduler\n",
    "    parser.add_argument('--lr_scheduler', type=str, default='StepLR', help='the type of the learning rate scheduler.')\n",
    "    parser.add_argument('--step_size', type=int, default=50, help='the step size of the learning rate scheduler.')\n",
    "    parser.add_argument('--gamma', type=float, default=0.1, help='the gamma of the learning rate scheduler.')\n",
    "\n",
    "    # Others\n",
    "    parser.add_argument('--seed', type=int, default=9233, help='.')\n",
    "    parser.add_argument('--resume', type=str, help='whether to resume the training from existing checkpoints.')\n",
    "    parser.add_argument('--num_prototype', type=int, default=10, help='.')\n",
    "    parser.add_argument('--num_cluster', type=int, default=20, help='.')\n",
    "    parser.add_argument('--weight_cnn_loss', type=float, default=0.5, help='.')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de7651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/iu_xray/iu_xray_labels.pickle','rb') as myfile:\n",
    "    labels = pickle.load(myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8b7696",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_protypes = np.zeros(len(labels),2048)\n",
    "counter=np.zeros(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ed4c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parse_agrs()\n",
    "tokenizer = Tokenizer(args)\n",
    "model = models.resnet101(pretrained=True)\n",
    "modules = list(model.children())[:-2]\n",
    "model = nn.Sequential(*modules)\n",
    "train_dataloader = R2DataLoader(args, tokenizer, split='train', shuffle=True,drop_last=True)\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "for batch_idx, (images_id, images, reports_ids, reports_masks) in enumerate(train_dataloader):\n",
    "    images, reports_ids, reports_masks = images.cuda(), reports_ids.cuda(), \\\n",
    "                                                 reports_masks.cuda()\n",
    "    features = model(images)\n",
    "    for i,report_id in enumerate(report_ids):\n",
    "        label = labels[report_id]\n",
    "        feature = features[i]\n",
    "        print(feature.shape)\n",
    "        counter[label]+=1\n",
    "        initial_protypes[label]+=feature.cpu().numpy()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
